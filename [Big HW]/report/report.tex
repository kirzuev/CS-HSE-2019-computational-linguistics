\documentclass[oneside,final,12pt]{article}

\usepackage[T2A]{fontenc}
%\usepackage[utf8]{inputenc}   % older versions of ucs package
\usepackage[utf8x]{inputenc}  % more recent versions (at least>=2004-17-10)
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{vmargin}
\setpapersize{A4}
\setmarginsrb{3cm}{2cm}{1.5cm}{2cm}{0pt}{0mm}{0pt}{13mm}
\usepackage{indentfirst}
\usepackage[footnotesize]{caption2}
\usepackage{alltt}
\usepackage{multicol}
\usepackage{hyperref}

\sloppy

% Параметры страницы
\textheight=24cm
\textwidth=16cm
\footnotesep=3ex
\raggedbottom
\tolerance 3000
% подавить эффект "висячих стpок"
\clubpenalty=10000
\widowpenalty=10000
\renewcommand{\baselinestretch}{1.1}
\renewcommand{\baselinestretch}{1.5} %для печати с большим интервалом

\begin{document}

\begin{titlepage}
\begin{center}

    Национальный исследовательский университет\\
    Высшая школа экономики\\
    Факультет компьютерных наук\\[60mm]
    \bigskip
    Отчет по итоговому домашнему заданию \\[5mm]   
    \textsf{\large\bfseries
         Реферирование/аннотирование текста на русском языке на основе статистики и эвристических правил
    }\\[50mm]

   
    \begin{flushright}
        \parbox{0.4\textwidth}{
            студент 1 курса магистратуры\\
            \emph{Зуев Кирилл Александрович}\\[5mm]
        }
    \end{flushright}

    \vspace{\fill}
    Москва, 2019
\end{center}
\end{titlepage}

\newpage

\renewcommand{\contentsname}{Содержание}
\tableofcontents

\newpage

\section{Постановка задачи}

Реализовать один или несколько методов автоматического аннотирования (построения реферата) текста. Провести экспериментальное исследование построения аннотаций нескольких выбранных текстов с использованием различных параметров для реализованных методов.

\section{Уточнение постановки задачи}

Для начала, когда на вход программе подается <<сырой>> текст, нужно его разбить на предложения для того, чтобы из них оставить наиболее значимые. Это я и выполнил в первой части программы. Сделал я это достаточно примитивно, по соответсвующим знакам препинания, которые обычно обозначают конец предложения. А именно: точка (\textbf{.}), восклицательный (\textbf{!}) и вопросительный (\textbf{?}) знаки.\\

Я реализовал несколько методов аннотирования текстов:
\begin{itemize}
	\item \textbf{SumBasic};
	\item \textbf{TF-IDF};
	\item на основе \textbf{графа предложений}.
\end{itemize}

Были рассмотрены разные степени сжатия текста:
\begin{multicols}{3}
	\begin{itemize}
		\item 20\%;
	\end{itemize}
	\begin{itemize}
		\item 30\%;
	\end{itemize}
	\begin{itemize}
		\item 40\%.
	\end{itemize}
\end{multicols}

Для метода на основе графа предложений я использовал разные пороги степени сходства предложений:
\begin{multicols}{3}
	\begin{itemize}
		\item 0.2;
	\end{itemize}
	\begin{itemize}
		\item 0.3;
	\end{itemize}
	\begin{itemize}
		\item 0.4.
	\end{itemize}
\end{multicols}

Для проведения экспериментов я выбрал следующие тексты:
\begin{itemize}
	\item \href{https://the-flow.ru/features/mstiteli-final-review}{Рецензия на фильм <<Мстители: Финал>>};
	\item \href{https://the-flow.ru/features/novyy-epizod-igry-prestolov-pochemu-on-razocharoval}{Рецензия на 3 эпизод нового сезона <<Игры престолов>>};
	\item \href{https://the-flow.ru/news/na-rep-festivale-v-moskve-policiya-i-rosgvardiya-izbila-shkolnikov}{Комментарий Noize MC о произошедшей стычке 1 мая в Лужниках};
\end{itemize}

\section{Описание реализованных методов}

Стоит отметить, что в каждом из методов <<слова>> представляют собой леммы (нормальные формы) лексем, встречающихся в тексте.

\subsection{SumBasic}

Идея метода состоит в том, что наиболее частотные слова текста с большой вероятностью должны оказаться в аннотации.\\

Для выбора очередного предложения подсчитывается вес всех предложений:
$$
weight(S_j) = \sum_{w_i \in S_j} \frac{p(w_i)}{| \{w_i~|~w_i \in S_j\} |},
$$
где $S_j$ --- $j$-е предложение текста, $w_i$ --- $i$-е слово в предложении, а $p(w_i)$ --- вероятность появления слова $w_i$ в тексте:
$$
p(w_i) = \frac{n}{N},
$$
где $n$ --- число вхождений слова $w_i$ в текст, а $N$ --- общее число слов в тексте.\\

В аннотацию на каждом шаге выбирается предложение с наибольшим весом. После выбора предложения происходит пересчёт весов для предложений, не вошедших в аннотацию. И выбор уже происходит из оставшихся предложений.

\subsection{TF-IDF}

Данный метод отличается от метода \textbf{SumBasic} вычислением <<ценности>> слова. Теперь она определяется не вероятностью его появления в тексте, а таким образом, что чем реже оно встречается в различных предложениях, тем оно более информативно. Вес слова $p(w_i)$ определяется по формуле:
$$
p(w_i) = tf(w_i, S_j) * idf(w_i, T),
$$
где $T$ --- текст, $S_j$ --- $j$-е предложение текста, $w_i$ --- $i$-е слово в предложении.
\clearpage

Значения функций $tf$ и $idf$ вычисляются следующим образом:
$$
tf(w_i, S_j) = \frac{n_{w_i}}{\sum_k{n_{w_k}}},
$$
$$
idf(w_i, T) = log \frac{|T|}{| \{S_j \in T~|~w_i \in S_j\} |},
$$
где $n_{w_k}$ --- число вхождений слова $w_k$ в предложение $S_j$, $\sum_k{n_{w_k}}$ --- общее число слов в предложении $S_j$, $|T|$ --- число предложений в тексте, а $| \{S_j \in T~|~w_i \in S_j\} |$ --- число предложений из текста, в которых встречается слово $w_i$.\\

В аннотацию на каждом шаге выбирается предложение с наибольшим весом. После каждого выбора происходит пересчёт весов для предложений, не вошедших в аннотацию. И выбор уже происходит из оставшихся предложений.

\subsection{На основе графа предложений}

В данном методе для каждого предложения ставится в соответствие вектор, значения в каждой координате которого определяются количеством вхождений определенного слова в это предложение.\\

Далее строится граф, вершинами которого являются сами предложения, а наличие дуг между парой вершин означает, что соответствующие предложения имеют схожесть не ниже заданного порога $\theta$:
$$
similarity(v_i, v_j) = cos(v_i, v_j) = \frac{(v_i, v_j)}{||v_i||_2~||v_j||_2} \geq \theta,
$$
где $v_i$, $v_j$ --- векторы соответственно $i$-го и $j$-го предложений.\\

Для каждой вершины графа вычисляется значение центральности по ее степени (числу ребер, инцидентных с этой вершиной). Предложения с наибольшими значениями центральности       выбираются в аннотацию.

\section{Код программы}

Реализация программы находится в приложенных файлах \textbf{Big\_HW.html} и \textbf{Big\_HW.ipynb}.

\section{Полученные результаты}

Результаты эксперимента можно увидеть в конце кода программы, где представлены аннотации, полученные для всех рассматриваемых текстов, для всех моделей и параметров.

\section{Выводы по исследованию}

По результатам проведенного эксперимента можно заметить, что метод \textbf{SumBasic} выдает предложения, в которых встречаются наиболее частотные слова, но чаще всего они не отражают всей сути исходного текста. Метод \textbf{TF-IDF} в большинстве случаев выдает короткие предложения, что тоже редко передает смысл текста. Метод на основе \textbf{графа предложений}, по моему мнению, дает наиболее удачные аннотации, учитывающие схожесть предложений, а не использующие исключительно частотность слов. Из рассмотренных порогов образования дуг в графе я считаю оптимальным значением --- $0.2$, поскольку оно допускает больше связей, чем $0.3$ или $0.4$ (но с меньшей степенью схожести). По объему аннотации я считаю, что оптимально выбрать $30$ или $40\%$ предложений от исходного текста, поскольку в $20\%$ труднее передать всю суть, а больше уже будет слишком много для короткой аннотации.

\end{document}
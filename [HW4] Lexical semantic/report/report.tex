\documentclass[oneside,final,12pt]{article}

\usepackage[T2A]{fontenc}
%\usepackage[utf8]{inputenc}   % older versions of ucs package
\usepackage[utf8x]{inputenc}  % more recent versions (at least>=2004-17-10)
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{vmargin}
\setpapersize{A4}
\setmarginsrb{3cm}{2cm}{1.5cm}{2cm}{0pt}{0mm}{0pt}{13mm}
\usepackage{indentfirst}
\usepackage[footnotesize]{caption2}
\usepackage{alltt}
\usepackage{hyperref}
\usepackage{multicol}

\sloppy

% Параметры страницы
\textheight=24cm
\textwidth=16cm
\footnotesep=3ex
\raggedbottom
\tolerance 3000
% подавить эффект "висячих стpок"
\clubpenalty=10000
\widowpenalty=10000
\renewcommand{\baselinestretch}{1.1}
\renewcommand{\baselinestretch}{1.5} %для печати с большим интервалом

\begin{document}

\begin{titlepage}
\begin{center}

    Национальный исследовательский университет\\
    Высшая школа экономики\\
    Факультет компьютерных наук\\[60mm]
    \bigskip
    Отчет по домашнему заданию №4 \\[5mm]   
    \textsf{\large\bfseries
         Лексическая семантика
    }\\[50mm]

   
    \begin{flushright}
        \parbox{0.4\textwidth}{
            студент 1 курса магистратуры\\
            \emph{Зуев Кирилл Александрович}\\[5mm]
        }
    \end{flushright}

    \vspace{\fill}
    Москва, 2019
\end{center}
\end{titlepage}

\newpage

\renewcommand{\contentsname}{Содержание}
\tableofcontents

\newpage

\section{Постановка задачи выбранного варианта (C)}

На основе уже обученной модели \textbf{Word2Vec} (векторного представления слов) для русского языка, взятой, например, из библиотеки \href{https://radimrehurek.com/gensim/models/word2vec.html}{\textbf{Gensim}}  или с \href{http://rusvectores.org/ru/models/}{сайта с различными векторными моделями для РЯ}, провести экспериментальное исследование семантики нескольких (5--9) выбранных слов (достаточно частотных, разных частей речи): найти семантически близкие и характеризующие слова, определить близость пар слов, а также исследовать другие операции, допускаемые моделью.

За дополнительные баллы: рассмотреть несколько разных (2--3) обученных векторных моделей и сравнить результаты в них для выбранных слов.

\section{Уточнение постановки задачи}

Для эксперимента я рассмотрел встроенную в \textbf{Gensim} модель (обученную на \textbf{НКРЯ}) и 3 векторные модели для РЯ с сайта:

\begin{itemize}
	\item \textbf{НКРЯ};
	\item \textbf{НКРЯ} и \textbf{Wikipedia};
	\item \textbf{Тайга}.
\end{itemize}

Для исследования я выбрал 9 слов разных частей речи:

\begin{multicols}{2}
	\begin{itemize}
		\item {существительные:
			\begin{itemize}
				\item \textit{кот};
				\item \textit{одежда};
				\item \textit{машина};
			\end{itemize}}
		\item {прилагательные:
			\begin{itemize}
				\item \textit{красный};
				\item \textit{большой};
			\end{itemize}}
		\vfill\null
		\columnbreak
		\item {глаголы:
			\begin{itemize}
				\item \textit{делать};
				\item \textit{говорить};
			\end{itemize}}
		\item наречие \textit{хорошо};
		\item числительное \textit{мало}.
		\vfill\null
	\end{itemize}
\end{multicols}
\clearpage

\section{Характеристика использованных моделей}

\subsection{Встроенная в Gensim модель}

\begin{itemize}
	\item Идентификатор: \textbf{word2vec-ruscorpora-300};
	\item Корпус: \textbf{НКРЯ};
	\item Размер корпуса: 250 млн.;
	\item Объём словаря: 185 тыс.;
	\item Размерность вектора: 300;
	\item Размер окна: 10.
\end{itemize}

\subsection{Модель с сайта, обученная на корпусе НКРЯ}

\begin{itemize}
	\item Идентификатор:  \textbf{ruscorpora\_upos\_cbow\_300\_20\_2019};
	\item Корпус: \textbf{НКРЯ};
	\item Размер корпуса: 270 млн.;
	\item Объём словаря: 189 тыс.;
	\item Размерность вектора: 300;
	\item Размер окна: 20.
\end{itemize}

\subsection{Модель с сайта, обученная на корпусе НКРЯ и Wikipedia}

\begin{itemize}
	\item Идентификатор:  \textbf{ruwikiruscorpora\_upos\_skipgram\_300\_2\_2019};
	\item Корпус: \textbf{НКРЯ} и \textbf{Wikipedia};
	\item Размер корпуса: 788 млн.;
	\item Объём словаря: 249 тыс.;
	\item Размерность вектора: 300;
	\item Размер окна: 2.
\end{itemize}

\subsection{Модель с сайта, обученная на корпусе Тайга}

\begin{itemize}
	\item Идентификатор:  \textbf{tayga\_upos\_skipgram\_300\_2\_2019};
	\item Корпус: \textbf{Тайга};
	\item Размер корпуса: 5 млрд.;
	\item Объём словаря: 250 тыс.;
	\item Размерность вектора: 300;
	\item Размер окна: 2.
\end{itemize}

\section{Проведённые эксперименты}

\subsection{Поиск семантически близких слов}

Для каждого из выбранных мной слов я нашел наиболее близкие.

\begin{itemize}
	\item {\textbf{\textit{кот}}\\
		Для разных моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{кошка}, \textit{котёнок}, \textit{пёс} и др. }
	\item {\textbf{\textit{морковь}}\\
		Для разных моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{капуста}, \textit{помидор}, \textit{картофель} и др.\\
		Но для модели, обученной на \textbf{НКРЯ}, на первых местах оказались слова \textit{сельдерей}, \textit{корнеплод} и \textit{укроп}, которые ещё встречаются во встроенной в \textbf{Gensim} модель, но не встречаются в остальных. }
	\item {\textbf{\textit{ботинок}}\\
		Для разных моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{сапог}, \textit{туфля}, \textit{башмак} и др.\\
		Но для модели, обученной на \textbf{НКРЯ}, на третьем месте оказалось слово \textit{полуботинок}, которое в целом довольно странное и не встречается ещё только во встроенной в \textbf{Gensim} модели. }
	\item {\textbf{\textit{красный}}\\
		Для разных моделей получились различные похожие слова, обозначающие либо близкие с красным (\textit{алый}, \textit{оранжевый} и \textit{малиновый}), либо другие цвета (\textit{синий}, \textit{белый} и \textit{зелёный}). }
	\item {\textbf{\textit{большой}}\\
		Для всех моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{огромный}, \textit{громадный}, \textit{небольшой} и др. }
	\item {\textbf{\textit{идти}}\\
		Для всех моделей самым близким оказалось слово \textit{пойти}. Также в большинстве моделей встречаются слова \textit{шагать},  \textit{бежать} и \textit{ехать}. }
	\item {\textbf{\textit{говорить}}\\
	Для разных моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{сказать}, \textit{рассуждать}, \textit{толковать} и др. }
	\item {\textbf{\textit{мало}}\\
		Для моделей с сайта получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{много}, \textit{больше}, \textit{мало} и др. А для встроенной в \textbf{Gensim} модели наиболее схожими оказались слова: \textit{мало}, \textit{менее}, \textit{немного} и др. }
	\item {\textbf{\textit{хорошо}}\\
		Для разных моделей получились примерно одинаковые результаты, с разными значениями близости получились слова: \textit{плохо}, \textit{отлично}, \textit{прекрасно} и др. }
\end{itemize}

\subsection{Вычисление близости пар слов}

Из рассматриваемых слов я составил всевозможные пары и посчитал их близость для модели, встроенной в \textbf{Gensim}. Затем я отсортировал их по значению полученной близости и вывел 10 наиболее похожих. Для этих 10 пар я также посчитал близость для моделей с сайта.
\clearpage

\begin{enumerate}
	\item \textit{делать} и \textit{говорить}: 0.420 (\textbf{НКРЯ}: 0.329, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.474, \textbf{Тайга}: 0.273);
	\item \textit{говорить} и \textit{хорошо}: 0.373 (\textbf{НКРЯ}: 0.120, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.394, \textbf{Тайга}: 0.215);
	\item \textit{мало} и \textit{хорошо}: 0.360 (\textbf{НКРЯ}: 0.214, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.326, \textbf{Тайга}: 0.183);
	\item \textit{большой} и \textit{мало}: 0.333 (\textbf{НКРЯ}: 0.294, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.386, \textbf{Тайга}: 0.218);
	\item \textit{кот} и \textit{ботинок}: 0.326 (\textbf{НКРЯ}: 0.232, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.352, \textbf{Тайга}: 0.247);
	\item \textit{делать} и \textit{хорошо}: 0.301 (\textbf{НКРЯ}: 0.081, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.298, \textbf{Тайга}: 0.135);
	\item \textit{красный} и \textit{большой}: 0.280 (\textbf{НКРЯ}: 0.182, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.330, \textbf{Тайга}: 0.215);
	\item \textit{большой} и \textit{хорошо}: 0.241 (\textbf{НКРЯ}: 0.218, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.277, \textbf{Тайга}: 0.118);
	\item \textit{кот} и \textit{говорить}: 0.239 (\textbf{НКРЯ}: -0.088, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.261, \textbf{Тайга}: 0.126);
	\item \textit{большой} и \textit{говорить}: 0.231 (\textbf{НКРЯ}: -0.036, \textbf{НКРЯ} и \textbf{Wikipedia}: 0.315, \textbf{Тайга}: 0.110).
\end{enumerate}

\section{Код программы}

Реализация программы для исследования встроенной в \textbf{Gensim} модели находится в приложенных файлах \textbf{HW4.pdf} и \textbf{HW4.ipynb}.
\clearpage

\section{Выводы по исследованию}

При поиске семантически близких для выбранного набора слов (достаточно частотных) в большинстве случаев с разными значениями близости выдавались примерно одинаковые результаты. В паре случаев для части моделей результаты отличались. Думаю, это связано с тем, что использовались разные корпусы разных объёмов и к тому же разные размеры окон. В целом на результат данного эксперимента это влияло не так сильно.

При вычислении близости пар выбранных слов результаты получились довольно разные. В первую очередь, это связано с тем, что все слова по смыслу отличаются друг от друга, а, во-вторых, значение близости очень зависит от параметров рассматриваемой модели и корпусе, на котором она обучена. Но для нескольких пар различия получились не очень большими, значит, они действительно в части случаев употребляются в одном и том же контексте или похожи по смыслу.

\end{document}